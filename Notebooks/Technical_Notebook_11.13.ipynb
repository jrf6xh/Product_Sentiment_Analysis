{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_text  9092 non-null   object\n",
      " 1   object      3291 non-null   object\n",
      " 2   sentiment   9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/data.csv', encoding='latin-1')\n",
    "df.rename(columns={'emotion_in_tweet_is_directed_at':'object', 'is_there_an_emotion_directed_at_a_brand_or_product':'sentiment'}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove row with missing text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_text  9092 non-null   object\n",
      " 1   object      3291 non-null   object\n",
      " 2   sentiment   9092 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 284.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(thresh=2, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>object</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text              object  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "          sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                5388\n",
       "Positive emotion    2978\n",
       "Negative emotion     570\n",
       "Unknown              156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].replace(\"I can't tell\", \"Unknown\", inplace=True)\n",
    "df['sentiment'].replace(\"No emotion toward brand or product\", \"None\", inplace=True)\n",
    "df['sentiment'].replace(\" emotion\", \"\", inplace=True)\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>object</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text              object  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "          sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tweet_text', 'object']]\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=18, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesfay/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "X_train.reset_index(inplace=True)\n",
    "X_train.drop('index', axis=1, inplace=True)\n",
    "X_test.reset_index(inplace=True)\n",
    "X_test.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List of stopwords & punctuation\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The '@' and '#' symbols carry special meaning in text on twitter and other social media platforms.  To include this meaning in the analysis, we'll remove these characters from the stopwords list.  The dataset also includes '{link}' in place of any actual url links.  We'll leave '{' and '}' in the text to reflect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list.remove('#')\n",
    "stopwords_list.remove('@')\n",
    "stopwords_list.remove('{')\n",
    "stopwords_list.remove('}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "    return stopwords_removed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = list(map(remove_stopwords, X_train['tweet_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ipad2 3 weeks w ipad since gave @ mention # sxsw withdrawal',\n",
       " 'rt @ mention first shots w/ipad 2 # sxsw { link }',\n",
       " \"rt @ mention ning amp mobile roadie thrilled offer unofficial # sxsw insider 's guide iphone fun austin { link }\",\n",
       " \"rt @ mention bounced catch google 's marissa mayer speak always admired intelligent classy successful # sxsw\",\n",
       " 'part journalsim support democracy yes informed populous yes ipad focus support # newsapps # sxsw']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_text_list = []\n",
    "for word_list in processed:\n",
    "    joined_text = ' '.join(word_list)\n",
    "    joined_text_list.append(joined_text)\n",
    "joined_text_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesfay/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train['processed_text'] = joined_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6819 entries, 0 to 6818\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   tweet_text      6819 non-null   object\n",
      " 1   object          2467 non-null   object\n",
      " 2   processed_text  6819 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 159.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>object</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No ipad2 for me. Now I have 3 weeks w no iPad ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ipad2 3 weeks w ipad since gave @ mention # sx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @mention First shots w/iPad 2 from #sxsw {l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rt @ mention first shots w/ipad 2 # sxsw { link }</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @mention Ning &amp;amp; Mobile Roadie are thril...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rt @ mention ning amp mobile roadie thrilled o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @mention Bounced over to catch Google's Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rt @ mention bounced catch google 's marissa m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Part of Journalsim is the support of democracy...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>part journalsim support democracy yes informed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text object  \\\n",
       "0  No ipad2 for me. Now I have 3 weeks w no iPad ...    NaN   \n",
       "1  RT @mention First shots w/iPad 2 from #sxsw {l...    NaN   \n",
       "2  RT @mention Ning &amp; Mobile Roadie are thril...    NaN   \n",
       "3  RT @mention Bounced over to catch Google's Mar...    NaN   \n",
       "4  Part of Journalsim is the support of democracy...   iPad   \n",
       "\n",
       "                                      processed_text  \n",
       "0  ipad2 3 weeks w ipad since gave @ mention # sx...  \n",
       "1  rt @ mention first shots w/ipad 2 # sxsw { link }  \n",
       "2  rt @ mention ning amp mobile roadie thrilled o...  \n",
       "3  rt @ mention bounced catch google 's marissa m...  \n",
       "4  part journalsim support democracy yes informed...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6819, 8530)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train['processed_text'])\n",
    "tf_idf_data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.8k tweets with 8.5k unique words in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline\n",
    "pipe_forest = Pipeline([('forest', RandomForestClassifier(random_state=70, n_jobs=-1, bootstrap=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid parameter\n",
    "grid_forest = [{'forest__n_estimators': [100, 200, 300],\n",
    "             'forest__max_depth': [1, 5, 15, 25, 50],\n",
    "             'forest__min_samples_split': [2, 5, 10, 25, 50], \n",
    "             'forest__min_samples_leaf': [1, 3, 5, 10, 25], \n",
    "             'forest__criterion': ['gini', 'entropy'],\n",
    "             'forest__max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'forest__max_samples': [None, .2, .5, .8]\n",
    "             }]\n",
    "\n",
    "# Create the grid, with \"pipe\" as the estimator\n",
    "gridsearch_forest = RandomizedSearchCV(estimator=pipe_forest, \n",
    "                          param_distributions=grid_forest, \n",
    "                          return_train_score=True, #Include training results in cv_results\n",
    "                          cv=5, #Use 5 folds in CV process\n",
    "                          n_iter=500, #Try 500 hyperparameter combinations\n",
    "                          n_jobs=-1, #Use paralell computing\n",
    "                          verbose=8) #Give updates on progress during fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1285 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1609 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2365 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed: 13.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('forest',\n",
       "                                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                                     random_state=70))]),\n",
       "                   n_iter=500, n_jobs=-1,\n",
       "                   param_distributions=[{'forest__criterion': ['gini',\n",
       "                                                               'entropy'],\n",
       "                                         'forest__max_depth': [1, 5, 15, 25,\n",
       "                                                               50],\n",
       "                                         'forest__max_features': ['auto',\n",
       "                                                                  'sqrt',\n",
       "                                                                  'log2'],\n",
       "                                         'forest__max_samples': [None, 0.2, 0.5,\n",
       "                                                                 0.8],\n",
       "                                         'forest__min_samples_leaf': [1, 3, 5,\n",
       "                                                                      10, 25],\n",
       "                                         'forest__min_samples_split': [2, 5, 10,\n",
       "                                                                       25, 50],\n",
       "                                         'forest__n_estimators': [100, 200,\n",
       "                                                                  300]}],\n",
       "                   return_train_score=True, verbose=8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_forest.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forest__n_estimators': 200,\n",
       " 'forest__min_samples_split': 10,\n",
       " 'forest__min_samples_leaf': 1,\n",
       " 'forest__max_samples': None,\n",
       " 'forest__max_features': 'auto',\n",
       " 'forest__max_depth': 50,\n",
       " 'forest__criterion': 'gini'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_forest__n_estimators</th>\n",
       "      <th>param_forest__min_samples_split</th>\n",
       "      <th>param_forest__min_samples_leaf</th>\n",
       "      <th>param_forest__max_samples</th>\n",
       "      <th>param_forest__max_features</th>\n",
       "      <th>param_forest__max_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.208170</td>\n",
       "      <td>0.196211</td>\n",
       "      <td>0.147405</td>\n",
       "      <td>0.048705</td>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634698</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>2</td>\n",
       "      <td>0.710174</td>\n",
       "      <td>0.711641</td>\n",
       "      <td>0.707241</td>\n",
       "      <td>0.710907</td>\n",
       "      <td>0.701979</td>\n",
       "      <td>0.708389</td>\n",
       "      <td>0.003536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2.351125</td>\n",
       "      <td>0.147367</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632644</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>3</td>\n",
       "      <td>0.676077</td>\n",
       "      <td>0.673877</td>\n",
       "      <td>0.669661</td>\n",
       "      <td>0.670761</td>\n",
       "      <td>0.669172</td>\n",
       "      <td>0.671909</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>7.955804</td>\n",
       "      <td>0.655432</td>\n",
       "      <td>0.208804</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632350</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>5</td>\n",
       "      <td>0.694225</td>\n",
       "      <td>0.694959</td>\n",
       "      <td>0.693126</td>\n",
       "      <td>0.698808</td>\n",
       "      <td>0.690982</td>\n",
       "      <td>0.694420</td>\n",
       "      <td>0.002572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>7.747250</td>\n",
       "      <td>0.177960</td>\n",
       "      <td>0.216324</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632350</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>5</td>\n",
       "      <td>0.694225</td>\n",
       "      <td>0.694959</td>\n",
       "      <td>0.693126</td>\n",
       "      <td>0.698808</td>\n",
       "      <td>0.690982</td>\n",
       "      <td>0.694420</td>\n",
       "      <td>0.002572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>7.464928</td>\n",
       "      <td>0.134755</td>\n",
       "      <td>0.173347</td>\n",
       "      <td>0.052346</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640270</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.737672</td>\n",
       "      <td>0.738955</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.739002</td>\n",
       "      <td>0.003215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>6.230466</td>\n",
       "      <td>0.274357</td>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.043996</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632351</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>4</td>\n",
       "      <td>0.698625</td>\n",
       "      <td>0.696792</td>\n",
       "      <td>0.693309</td>\n",
       "      <td>0.696792</td>\n",
       "      <td>0.692815</td>\n",
       "      <td>0.695667</td>\n",
       "      <td>0.002235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "93        5.208170      0.196211         0.147405        0.048705   \n",
       "333       2.351125      0.147367         0.108140        0.001314   \n",
       "416       7.955804      0.655432         0.208804        0.001331   \n",
       "486       7.747250      0.177960         0.216324        0.005877   \n",
       "492       7.464928      0.134755         0.173347        0.052346   \n",
       "494       6.230466      0.274357         0.129779        0.043996   \n",
       "\n",
       "    param_forest__n_estimators param_forest__min_samples_split  \\\n",
       "93                         200                              25   \n",
       "333                        100                              10   \n",
       "416                        300                              50   \n",
       "486                        300                              50   \n",
       "492                        200                              10   \n",
       "494                        200                              50   \n",
       "\n",
       "    param_forest__min_samples_leaf param_forest__max_samples  \\\n",
       "93                               1                       0.8   \n",
       "333                              3                       0.8   \n",
       "416                              1                       0.8   \n",
       "486                              1                       0.8   \n",
       "492                              1                      None   \n",
       "494                              1                       0.8   \n",
       "\n",
       "    param_forest__max_features param_forest__max_depth  ... mean_test_score  \\\n",
       "93                        sqrt                      50  ...        0.634698   \n",
       "333                       auto                      50  ...        0.632644   \n",
       "416                       auto                      50  ...        0.632350   \n",
       "486                       sqrt                      50  ...        0.632350   \n",
       "492                       auto                      50  ...        0.640270   \n",
       "494                       auto                      50  ...        0.632351   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "93        0.007771                2            0.710174            0.711641   \n",
       "333       0.004954                3            0.676077            0.673877   \n",
       "416       0.006633                5            0.694225            0.694959   \n",
       "486       0.006633                5            0.694225            0.694959   \n",
       "492       0.006793                1            0.743355            0.737672   \n",
       "494       0.006578                4            0.698625            0.696792   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "93             0.707241            0.710907            0.701979   \n",
       "333            0.669661            0.670761            0.669172   \n",
       "416            0.693126            0.698808            0.690982   \n",
       "486            0.693126            0.698808            0.690982   \n",
       "492            0.738955            0.741155            0.733871   \n",
       "494            0.693309            0.696792            0.692815   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "93           0.708389         0.003536  \n",
       "333          0.671909         0.002650  \n",
       "416          0.694420         0.002572  \n",
       "486          0.694420         0.002572  \n",
       "492          0.739002         0.003215  \n",
       "494          0.695667         0.002235  \n",
       "\n",
       "[6 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_forest_df = pd.DataFrame.from_dict(gridsearch_forest.cv_results_)\n",
    "best_models = gridsearch_forest_df.loc[gridsearch_forest_df['rank_test_score'] < 6]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
